{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 繁體中文詞性標註系統 by CKIP transformers\n",
        "#### 詞性標記使用辭典：中研院資訊所、語言所詞庫小組所編技術報告第 95-02/98-04 ：https://asbc.iis.sinica.edu.tw/\n",
        "#### Cite：此開源碼來自中研院CKIP Lab：https://github.com/ckiplab/ckip-transformers\n",
        "#### Modified by：國立清華大學電機所  賴彥霖\n"
      ],
      "metadata": {
        "id": "CWXju4la-Mic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 登入Google 帳號"
      ],
      "metadata": {
        "id": "BU6Z1JMt-O_D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAJp5-bk-H9E",
        "outputId": "4758c156-797c-4fe4-ef1b-37f3c79829bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 安裝套件"
      ],
      "metadata": {
        "id": "u1P_54oDNyEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ckip_transformers\n",
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "yRnQynRdJTc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbc09b8c-31a3-414a-cf69-4c2d14adedbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ckip_transformers\n",
            "  Downloading ckip_transformers-0.3.4-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from ckip_transformers) (2.4.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from ckip_transformers) (4.66.5)\n",
            "Requirement already satisfied: transformers>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from ckip_transformers) (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip_transformers) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip_transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip_transformers) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip_transformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip_transformers) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip_transformers) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->ckip_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip_transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip_transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->ckip_transformers) (1.3.0)\n",
            "Downloading ckip_transformers-0.3.4-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ckip_transformers\n",
            "Successfully installed ckip_transformers-0.3.4\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 導入套件"
      ],
      "metadata": {
        "id": "1icbpTUqN3im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from tool import pos"
      ],
      "metadata": {
        "id": "mxZDkxT_JX3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 更改filename為欲分析的逐字稿檔名：下方將列出檔案中逐字稿內容\n",
        "##### 注意事項1：檔名外需有引號 ' ' 包覆，如 '111050001_task2.xlsx'\n",
        "##### 注意事項2：檔名需有檔案類型，如'111050008_task2.xlsx'，不可為'111050008_task2'，只接受excel檔。"
      ],
      "metadata": {
        "id": "HlU6d9OlGS8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 直接將統計完數據儲存至雲端硬碟"
      ],
      "metadata": {
        "id": "Lujw0iVoN8Ke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '111050005_task1.xlsx'\n",
        "pos(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "q11IhIUdJKZy",
        "outputId": "824cff2f-44fa-44aa-d026-3b5ba81939df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenization: 100%|██████████| 12/12 [00:00<00:00, 19668.48it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
            "Tokenization: 100%|██████████| 12/12 [00:00<00:00, 17654.03it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
            "Tokenization: 100%|██████████| 12/12 [00:00<00:00, 20173.01it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your file has been saved to /content/drive/MyDrive/詞性分析逐字稿/111050005_task1.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (舊版)下方可顯示每句詞性標註結果\n"
      ],
      "metadata": {
        "id": "bx_9xNvmYY2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = '111050064_task2.xlsx'\n",
        "dirpath = '/content/drive/MyDrive/逐字稿/所有逐字稿excel'\n",
        "file_path = os.path.join(dirpath, filename)\n",
        "df = pd.read_excel(file_path, usecols=[\"Content\"])\n",
        "print(df)\n",
        "\n",
        "pos_EtoC = { \"A\":\"形容詞\" ,\"Caa\":\"X\", \"Cab\":\"X\", \"Cba\":\"X\", \"Cbb\":\"X\", \"D\":\"副詞\", \"Da\":\"X\", \"Dfa\":\"副詞\", \"Dfb\":\"副詞\",\n",
        "        \"Di\":\"X\", \"Dk\":\"X\", \"DM\":\"X\", \"I\":\"X\", \"Na\":\"名詞\", \"Nb\":\"名詞\", \"Nc\":\"名詞\", \"Ncd\":\"名詞\", \"Nd\":\"X\", # \"Nd\":\"時間詞\",\n",
        "        \"Nep\":\"代名詞\", \"Neqa\":\"形容詞\", \"Neqb\":\"X\", \"Nes\":\"X\", \"Neu\":\"X\", # \"Neu\":\"數詞定詞\",\n",
        "        \"Nf\":\"X\", \"Ng\":\"X\", \"Nh\":\"代名詞\", \"Nv\":\"X\", \"P\":\"X\", # \"P\":\"介詞\",\n",
        "        \"T\":\"X\", # \"T\":\"語助詞\",\n",
        "        \"VA\":\"動詞\", \"VAC\":\"動詞\", \"VB\":\"動詞\", \"VC\":\"動詞\", \"VCL\":\"X\", \"VD\":\"動詞\", \"VF\":\"動詞\", \"VE\":\"動詞\", \"VG\":\"動詞\", \"VH\":\"形容詞\", \"VHC\":\"動詞\", \"VI\":\"動詞\",\n",
        "        \"VJ\":\"動詞\", \"VK\":\"動詞\", \"VL\":\"動詞\", \"V_2\":\"有\", \"DE\":\"的之得地\", \"SHI\":\"是\",\"FW\":\"X\",\n",
        "        \"COLONCATEGORY\":\"X\", \"COMMACATEGORY\":\"X\", \"DASHCATEGORY\":\"X\", \"DOTCATEGORY\":\"X\", \"ETCCATEGORY\":\"X\", \"EXCLAMATIONCATEGORY\":\"X\", \"PARENTHESISCATEGORY\":\"X\",\n",
        "        \"PAUSECATEGORY\":\"X\", \"PERIODCATEGORY\":\"X\", \"QUESTIONCATEGORY\":\"X\", \"SEMICOLONCATEGORY\":\"X\", \"SPCHANGECATEGORY\":\"X\", \"WHITESPACE\":\"X\", \"X\":\"X\"}\n",
        "# Initialize drivers\n",
        "ws_driver  = CkipWordSegmenter(model=\"bert-base\")\n",
        "pos_driver = CkipPosTagger(model=\"bert-base\")\n",
        "ner_driver = CkipNerChunker(model=\"bert-base\")\n",
        "# Save transcripts to list\n",
        "text = []\n",
        "for i in range(len(df)):\n",
        "   text.append(df[\"Content\"].iloc[i])\n",
        "# Enable sentence segmentation\n",
        "ws  = ws_driver(text, use_delim=True)\n",
        "ner = ner_driver(text, use_delim=True)\n",
        "pos = pos_driver(ws, delim_set='\\n\\t')\n",
        "# Pack word segmentation and part-of-speech results\n",
        "def pack_ws_pos_sentece(sentence_ws, sentence_pos):\n",
        "   assert len(sentence_ws) == len(sentence_pos)\n",
        "   res = []\n",
        "   for word_ws, word_pos in zip(sentence_ws, sentence_pos):\n",
        "      if word_pos == \"X\":\n",
        "        res.append(f\"{word_ws}\")\n",
        "      else:\n",
        "        res.append(f\"{word_ws}({word_pos})\")\n",
        "   return \"\\u3000\".join(res)\n",
        "# Show results\n",
        "exclude = [\"(\", \")\", \"（\", \"台\", \"）\", \"，\", \"。\", \"...\", \"..\", \".\", \" \", \"?\", \"？\", \"!\", \"、\"]\n",
        "total_counts = [0]*8\n",
        "print()\n",
        "for sentence, sentence_ws, sentence_pos in zip(text, ws, pos): #會迭代每句的分詞、詞性(英文)\n",
        "  print()\n",
        "  print(sentence)\n",
        "  sen_counts = [0]*8\n",
        "  pos_ch = []\n",
        "  for i in range(len(sentence_pos)):\n",
        "    if sentence_ws[i]==\"有\":\n",
        "      if sentence_ws[i-1] == \"還\":\n",
        "        sentence_pos[i] = \"X\"\n",
        "      elif pos_EtoC[sentence_pos[i+1]] == \"動詞\":\n",
        "        sentence_pos[i] = \"X\"\n",
        "      else:\n",
        "        sentence_pos[i] = \"VA\"\n",
        "\n",
        "    if sentence_ws[i] == \"台\":\n",
        "      sentence_pos[i] = \"X\"\n",
        "    pos_ch.append(pos_EtoC[sentence_pos[i]])\n",
        "  new_sentence_ws = []                  # 新的分詞和詞性列表\n",
        "  new_sentence_pos = []\n",
        "  i = 0\n",
        "  while i < len(sentence_ws):              # 遍歷詞和詞性，進行合併操作\n",
        "      if pos_ch[i] == '形容詞' and i + 1 < len(sentence_ws) and pos_ch[i + 1] == '的之得地':\n",
        "          new_sentence_ws.append(sentence_ws[i] + sentence_ws[i + 1])   # 合併形容詞和的之得地\n",
        "          new_sentence_pos.append('形容詞')\n",
        "          i += 2  # 跳過下一個詞\n",
        "      else:\n",
        "          new_sentence_ws.append(sentence_ws[i])  # 否則正常添加\n",
        "          new_sentence_pos.append(pos_ch[i])\n",
        "          i += 1\n",
        "  for i in range(len(new_sentence_pos)):\n",
        "    # if new_sentence_pos[i] not in exclude:  #不計算標點符號到字數統計量\n",
        "    if new_sentence_ws[i] not in exclude:      #不計算台語標註的(台)為字數統計量\n",
        "      sen_counts[0] += len(new_sentence_ws[i])\n",
        "      sen_counts[1] += 1\n",
        "      if new_sentence_pos[i] == \"名詞\":\n",
        "        sen_counts[2] += 1\n",
        "      elif new_sentence_pos[i] == \"代名詞\":\n",
        "        sen_counts[3] += 1\n",
        "      elif new_sentence_pos[i] == \"動詞\":\n",
        "        sen_counts[4] += 1\n",
        "      elif new_sentence_pos[i] == \"形容詞\":\n",
        "        sen_counts[5] += 1\n",
        "      elif new_sentence_pos[i] == \"副詞\":\n",
        "        sen_counts[6] += 1\n",
        "      else:\n",
        "        continue\n",
        "  print(pack_ws_pos_sentece(new_sentence_ws, new_sentence_pos))\n",
        "  print(\"{:=^50s}\".format(\"\"))\n",
        "  sentence_variables = [(\"@字數統計：\", sen_counts[0]), (\"@詞彙量：  \", sen_counts[1]), (\"名詞：     \",sen_counts[2],\" 比例：\",\"{:.2%}\".format(sen_counts[2]/sen_counts[1])),\n",
        "   (\"代名詞：   \",sen_counts[3],\" 比例：\",\"{:.2%}\".format(sen_counts[3]/sen_counts[1])),  (\"動詞：     \",sen_counts[4],\" 比例：\",\"{:.2%}\".format(sen_counts[4]/sen_counts[1])),\n",
        "    (\"形容詞：   \",sen_counts[5],\" 比例：\",\"{:.2%}\".format(sen_counts[5]/sen_counts[1])), (\"副詞：     \",sen_counts[6],\" 比例：\",\"{:.2%}\".format(sen_counts[6]/sen_counts[1]))]\n",
        "  for label, variable, *ratio in sentence_variables:\n",
        "    print(label, variable, *ratio)\n",
        "  for i in range(len(total_counts)):\n",
        "      total_counts[i] += sen_counts[i]\n",
        "  print()\n",
        "  total_counts[7] += 1\n",
        "print()\n",
        "print(\"【總統計量】\")\n",
        "total_variables = [(\"總字數：\", total_counts[0]), (\"總詞彙：\", total_counts[1]), (\"總句數：\", total_counts[7]), (\"名詞：   \", total_counts[2],\" 比例：\",\"{:.2%}\".format(total_counts[2]/total_counts[1])),(\"代名詞： \", total_counts[3],\" 比例：\",\"{:.2%}\".format(total_counts[3]/total_counts[1])),\n",
        "          (\"動詞：   \", total_counts[4],\" 比例：\",\"{:.2%}\".format(total_counts[4]/total_counts[1])), (\"形容詞： \", total_counts[5],\" 比例：\",\"{:.2%}\".format(total_counts[5]/total_counts[1])), (\"副詞：   \", total_counts[6],\" 比例：\",\"{:.2%}\".format(total_counts[6]/total_counts[1]))]\n",
        "for label, variable, *totalratio in total_variables:\n",
        "    print(label, variable, *totalratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o61ISkLEP1F",
        "outputId": "2a186b53-9602-4297-d59e-6314d6b0ff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Content\n",
            "0       這拿東西很危險\n",
            "1  好像這個是東西.掉下來了\n",
            "2         就這樣而已\n",
            "3       幾個人喔三個人\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Tokenization: 100%|██████████| 4/4 [00:00<00:00, 4941.74it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
            "Tokenization: 100%|██████████| 4/4 [00:00<00:00, 17367.72it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
            "Tokenization: 100%|██████████| 4/4 [00:00<00:00, 18724.57it/s]\n",
            "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "這拿東西很危險\n",
            "這(代名詞)　拿(動詞)　東西(名詞)　很(副詞)　危險(形容詞)\n",
            "==================================================\n",
            "@字數統計： 7\n",
            "@詞彙量：   5\n",
            "名詞：      1  比例： 20.00%\n",
            "代名詞：    1  比例： 20.00%\n",
            "動詞：      1  比例： 20.00%\n",
            "形容詞：    1  比例： 20.00%\n",
            "副詞：      1  比例： 20.00%\n",
            "\n",
            "\n",
            "好像這個是東西.掉下來了\n",
            "好像(副詞)　這(代名詞)　個　是(是)　東西(名詞)　.　掉下來(動詞)　了\n",
            "==================================================\n",
            "@字數統計： 11\n",
            "@詞彙量：   7\n",
            "名詞：      1  比例： 14.29%\n",
            "代名詞：    1  比例： 14.29%\n",
            "動詞：      1  比例： 14.29%\n",
            "形容詞：    0  比例： 0.00%\n",
            "副詞：      1  比例： 14.29%\n",
            "\n",
            "\n",
            "就這樣而已\n",
            "就(副詞)　這樣(形容詞)　而已\n",
            "==================================================\n",
            "@字數統計： 5\n",
            "@詞彙量：   3\n",
            "名詞：      0  比例： 0.00%\n",
            "代名詞：    0  比例： 0.00%\n",
            "動詞：      0  比例： 0.00%\n",
            "形容詞：    1  比例： 33.33%\n",
            "副詞：      1  比例： 33.33%\n",
            "\n",
            "\n",
            "幾個人喔三個人\n",
            "幾　個　人(名詞)　喔　三　個　人(名詞)\n",
            "==================================================\n",
            "@字數統計： 7\n",
            "@詞彙量：   7\n",
            "名詞：      2  比例： 28.57%\n",
            "代名詞：    0  比例： 0.00%\n",
            "動詞：      0  比例： 0.00%\n",
            "形容詞：    0  比例： 0.00%\n",
            "副詞：      0  比例： 0.00%\n",
            "\n",
            "\n",
            "【總統計量】\n",
            "總字數： 30\n",
            "總詞彙： 22\n",
            "總句數： 4\n",
            "名詞：    4  比例： 18.18%\n",
            "代名詞：  2  比例： 9.09%\n",
            "動詞：    2  比例： 9.09%\n",
            "形容詞：  2  比例： 9.09%\n",
            "副詞：    3  比例： 13.64%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}